{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_adjusted_covariance(df1, df2, timestep, start_time, end_time, time_col, value_col):\n",
    "    \"\"\"\n",
    "    Compute a single covariance value for two stocks over a specified time range.\n",
    "    \n",
    "    Parameters:\n",
    "    - df1, df2: DataFrames with sorted integer times in column time_col and values in value_col\n",
    "    - timestep: float or int, the increment between time steps\n",
    "    - start_time, end_time: int, the inclusive time range to consider\n",
    "    - time_col, value_col: int, column indices for time and value columns\n",
    "    \n",
    "    Returns:\n",
    "    - covariance: float, the adjusted covariance scalar:\n",
    "      Cov(Yi, Yj) = 1/Q{ij} sum_{t in Q{ij}} Y_it * Y_jt \n",
    "    - df1 = stock_i, df2 = stock_j, Q{ij}=#{t: both Y_it and Y_jt are present (not missing)})\n",
    "    \"\"\"\n",
    "    # Adjust times to start from 0\n",
    "    t1 = np.array(df1.iloc[:, time_col]).astype(int)\n",
    "    t2 = np.array(df2.iloc[:, time_col]).astype(int)\n",
    "    # Calculate T to define the valid range\n",
    "    T = int((end_time - start_time) / timestep) + 1 # Length of the new dfs\n",
    "    \n",
    "    # Discard entries outside the range [0, T-1] (only keep masked range)\n",
    "    mask1 = (t1 - start_time >= 0) & (t1 - end_time <= 0)\n",
    "    mask2 = (t2 - start_time >= 0) & (t2 - end_time <= 0)\n",
    "    df1_filtered = df1[mask1]\n",
    "    df2_filtered = df2[mask2]\n",
    "\n",
    "    # change time col to [0,1,...,T-1]\n",
    "    df1_filtered.iloc[:, time_col] = (t1[mask1] - start_time) / timestep\n",
    "    df2_filtered.iloc[:, time_col] = (t2[mask2] - start_time) / timestep\n",
    "    \n",
    "    # Find common observation times (Q_{ij}) by merging on adjusted times\n",
    "    # This performs an inner join, meaning only rows with matching time values in both DataFrames will be kept.\n",
    "    merged = pd.merge(\n",
    "        df1_filtered[[time_col, value_col]],\n",
    "        df2_filtered[[time_col, value_col]],\n",
    "        on=time_col,\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # If no common times, return 0\n",
    "    if merged.empty:\n",
    "        return 0.0\n",
    "    # Compute the sum of products Y_{it} * Y_{jt}\n",
    "    sum_products = (merged.iloc[:, 1] * merged.iloc[:, 2]).sum()\n",
    "    covariance = sum_products / len(merged)\n",
    "    return covariance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute covariance matrix from log-returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_covariance(df1, df2):\n",
    "    \"\"\"\n",
    "    Compute a single covariance value for two stocks over the available time range.\n",
    "    \n",
    "    Parameters:\n",
    "    - df1, df2: DataFrames with 'index' (sorted integer times indices 0,1,2...) and 'log_return'\n",
    "    - all dfs should be over the same timeframe\n",
    "    Returns:\n",
    "    - covariance: float, the adjusted covariance scalar:\n",
    "      Cov(Yi, Yj) = 1/Q{ij} sum_{t in Q{ij}} Y_it * Y_jt \n",
    "    - df1 = stock_i, df2 = stock_j, Q{ij}=#{t: both Y_it and Y_jt are present (not missing)})\n",
    "    \"\"\"\n",
    "    \n",
    "    # Find common observation times (Q_{ij}) by merging on adjusted times\n",
    "    # This performs an inner join, meaning only rows with matching time values in both DataFrames will be kept.\n",
    "    merged = pd.merge(\n",
    "        df1[['index', 'log_return']],\n",
    "        df2[['index', 'log_return']],\n",
    "        on='index',\n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    # If no common times, return 0\n",
    "    if merged.empty:\n",
    "        return 0.0\n",
    "    # Compute the sum of products Y_{it} * Y_{jt}\n",
    "    sum_products = (merged.iloc[:, 1] * merged.iloc[:, 2]).sum()\n",
    "    covariance = sum_products / len(merged)\n",
    "    return covariance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USD_60_2022-2025/BNTUSD_60.parquet', 'USD_60_2022-2025/REPUSD_60.parquet', 'USD_60_2022-2025/CTSIUSD_60.parquet', 'USD_60_2022-2025/KARUSD_60.parquet', 'USD_60_2022-2025/BNCUSD_60.parquet', 'USD_60_2022-2025/BANDUSD_60.parquet', 'USD_60_2022-2025/KEEPUSD_60.parquet', 'USD_60_2022-2025/OGNUSD_60.parquet', 'USD_60_2022-2025/LSKUSD_60.parquet', 'USD_60_2022-2025/REPV2USD_60.parquet', 'USD_60_2022-2025/GNOUSD_60.parquet', 'USD_60_2022-2025/KNCUSD_60.parquet', 'USD_60_2022-2025/GHSTUSD_60.parquet', 'USD_60_2022-2025/MLNUSD_60.parquet', 'USD_60_2022-2025/ICXUSD_60.parquet', 'USD_60_2022-2025/RARIUSD_60.parquet', 'USD_60_2022-2025/YFIUSD_60.parquet', 'USD_60_2022-2025/MIRUSD_60.parquet', 'USD_60_2022-2025/LPTUSD_60.parquet', 'USD_60_2022-2025/CQTUSD_60.parquet', 'USD_60_2022-2025/KILTUSD_60.parquet', 'USD_60_2022-2025/RENUSD_60.parquet', 'USD_60_2022-2025/QTUMUSD_60.parquet', 'USD_60_2022-2025/SDNUSD_60.parquet', 'USD_60_2022-2025/OXTUSD_60.parquet', 'USD_60_2022-2025/SRMUSD_60.parquet', 'USD_60_2022-2025/ZRXUSD_60.parquet', 'USD_60_2022-2025/PHAUSD_60.parquet', 'USD_60_2022-2025/STORJUSD_60.parquet', 'USD_60_2022-2025/ANKRUSD_60.parquet', 'USD_60_2022-2025/OMGUSD_60.parquet', 'USD_60_2022-2025/MOVRUSD_60.parquet', 'USD_60_2022-2025/LRCUSD_60.parquet', 'USD_60_2022-2025/SUSHIUSD_60.parquet', 'USD_60_2022-2025/BADGERUSD_60.parquet', 'USD_60_2022-2025/COMPUSD_60.parquet', 'USD_60_2022-2025/BATUSD_60.parquet', 'USD_60_2022-2025/1INCHUSD_60.parquet', 'USD_60_2022-2025/DYDXUSD_60.parquet', 'USD_60_2022-2025/CHZUSD_60.parquet', 'USD_60_2022-2025/MKRUSD_60.parquet', 'USD_60_2022-2025/DASHUSD_60.parquet', 'USD_60_2022-2025/AXSUSD_60.parquet', 'USD_60_2022-2025/INJUSD_60.parquet', 'USD_60_2022-2025/NANOUSD_60.parquet', 'USD_60_2022-2025/PERPUSD_60.parquet', 'USD_60_2022-2025/PAXGUSD_60.parquet', 'USD_60_2022-2025/ENJUSD_60.parquet', 'USD_60_2022-2025/ETCUSD_60.parquet', 'USD_60_2022-2025/OCEANUSD_60.parquet', 'USD_60_2022-2025/ZECUSD_60.parquet', 'USD_60_2022-2025/SNXUSD_60.parquet', 'USD_60_2022-2025/CRVUSD_60.parquet', 'USD_60_2022-2025/EWTUSD_60.parquet', 'USD_60_2022-2025/SCUSD_60.parquet', 'USD_60_2022-2025/KAVAUSD_60.parquet', 'USD_60_2022-2025/OXYUSD_60.parquet', 'USD_60_2022-2025/DAIUSD_60.parquet', 'USD_60_2022-2025/SANDUSD_60.parquet', 'USD_60_2022-2025/MANAUSD_60.parquet', 'USD_60_2022-2025/MINAUSD_60.parquet', 'USD_60_2022-2025/XTZUSD_60.parquet', 'USD_60_2022-2025/EOSUSD_60.parquet', 'USD_60_2022-2025/FLOWUSD_60.parquet', 'USD_60_2022-2025/AUDUSD_60.parquet', 'USD_60_2022-2025/GRTUSD_60.parquet', 'USD_60_2022-2025/AAVEUSD_60.parquet', 'USD_60_2022-2025/WBTCUSD_60.parquet', 'USD_60_2022-2025/FILUSD_60.parquet', 'USD_60_2022-2025/KSMUSD_60.parquet', 'USD_60_2022-2025/UNIUSD_60.parquet', 'USD_60_2022-2025/BCHUSD_60.parquet', 'USD_60_2022-2025/XRPUSD_60.parquet', 'USD_60_2022-2025/LUNAUSD_60.parquet', 'USD_60_2022-2025/ALGOUSD_60.parquet', 'USD_60_2022-2025/AVAXUSD_60.parquet', 'USD_60_2022-2025/XLMUSD_60.parquet', 'USD_60_2022-2025/SHIBUSD_60.parquet', 'USD_60_2022-2025/BALUSD_60.parquet', 'USD_60_2022-2025/TRXUSD_60.parquet', 'USD_60_2022-2025/ADAUSD_60.parquet', 'USD_60_2022-2025/LINKUSD_60.parquet', 'USD_60_2022-2025/ATOMUSD_60.parquet', 'USD_60_2022-2025/USDCUSD_60.parquet', 'USD_60_2022-2025/LTCUSD_60.parquet', 'USD_60_2022-2025/XMRUSD_60.parquet', 'USD_60_2022-2025/USDTUSD_60.parquet', 'USD_60_2022-2025/MATICUSD_60.parquet', 'USD_60_2022-2025/EURUSD_60.parquet', 'USD_60_2022-2025/RAYUSD_60.parquet', 'USD_60_2022-2025/GBPUSD_60.parquet', 'USD_60_2022-2025/DOTUSD_60.parquet', 'USD_60_2022-2025/SOLUSD_60.parquet', 'USD_60_2022-2025/ETHUSD_60.parquet', 'USD_60_2022-2025/XDGUSD_60.parquet', 'USD_60_2022-2025/XBTUSD_60.parquet']\n"
     ]
    }
   ],
   "source": [
    "with open(\"USD_60_filenames_parquet.txt\", \"r\") as file:\n",
    "    filepaths = [line.strip() for line in file if line.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4857356274699452e-05 2.4857356274699452e-05\n"
     ]
    }
   ],
   "source": [
    "# Compute adjusted covariance\n",
    "df1 = pd.read_parquet(filepaths[0])\n",
    "df2 = pd.read_parquet(filepaths[1])\n",
    "\n",
    "cov12 = compute_covariance(df1, df2)\n",
    "cov21 = compute_covariance(df2, df1)\n",
    "print(cov12, cov21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symmetric covariance matrix:\n",
      "[[1.49556270e-04 2.48573563e-05 7.25334956e-05 ... 4.38941751e-05\n",
      "  5.46671869e-05 3.13944912e-05]\n",
      " [2.48573563e-05 6.48042293e-04 2.59410302e-05 ... 1.27746143e-05\n",
      "  1.62781736e-05 1.20186884e-05]\n",
      " [7.25334956e-05 2.59410302e-05 1.93590965e-04 ... 5.47049880e-05\n",
      "  7.22196204e-05 4.05847298e-05]\n",
      " ...\n",
      " [4.38941751e-05 1.27746143e-05 5.47049880e-05 ... 5.42416254e-05\n",
      "  5.44069788e-05 3.61869329e-05]\n",
      " [5.46671869e-05 1.62781736e-05 7.22196204e-05 ... 5.44069788e-05\n",
      "  1.14522982e-04 4.14788090e-05]\n",
      " [3.13944912e-05 1.20186884e-05 4.05847298e-05 ... 3.61869329e-05\n",
      "  4.14788090e-05 3.34184353e-05]]\n"
     ]
    }
   ],
   "source": [
    "# Build covariance matrix using adjusted PCA for missing data\n",
    "import numpy as np\n",
    "\n",
    "N = len(filepaths)\n",
    "C = np.zeros((N, N))\n",
    "dfs = [pd.read_parquet(fp) for fp in filepaths]\n",
    "\n",
    "for i in range(N):\n",
    "    for j in range(i, N):\n",
    "        cov = compute_covariance(dfs[i], dfs[j])\n",
    "        C[i, j] = cov\n",
    "        if j != i:\n",
    "            C[j, i] = cov  # make symmetric\n",
    "\n",
    "# Save covariance matrix to a .npy file\n",
    "# .npy is the best format for numpy arrays as it preserves the array structure and data type\n",
    "print(\"Symmetric covariance matrix:\")\n",
    "print(C)\n",
    "print(\"\\nCovariance matrix saved to 'covariance_matrix.npy'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('USD_60_2022_01_01-2025_03_31_covariance_logreturn.npy', C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
